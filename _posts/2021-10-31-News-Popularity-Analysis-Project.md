### For the [GitHub page project 2 repo](https://github.com/IlanaFeldman/ST558-Project-2)

### For the [usual rendered project 2 repo](https://IlanaFeldman.github.io/ST558-Project-2/)

1. What would you do differently?
   
   I think I will fit a principal component analysis using all the predictors in the data and use the first few principal components which account for the most variations in the data to fit a linear regression for predition and see if the prediction from those PCs are better than my current models. I am actually very interested to find out. The study collected and retrieved a lot of attributes/features from those published articles on Mashable. They contain all the information about those articles. It seems like a waste when we only picked ten predictors to work with in our predictive models because we actually threw away a lot of information about our target variable. On top of that, a lot of the predictors are highly correlated with one another such as those LDA topic measures, average keywords based on average shares, minimum keywords, maximum keywords, best keywords, worst keywords and their corresponding minimums and maximums, and a lot of others. Hence, using PCA to group those highly correlated predictors together sounds logical. PCA will reduce a lot of predictors but the reduced number of PCs produced by PCA will still contain the most information about those articles.
   
2. What was the most difficult thing?
   
   I think the automation of the reports is the most difficult part especially I have no knowledge about how R Project is linked to GitHub repo. The plots produced by one channel report are overwritten by the plots produced by the next channel report generated. So at the end, I only have plots generated by one reports instead of six reports and they are placed in the wrong report as well. I am super confused about how GitHub is able to link the correct plot to the correct report at the correct place in the report. I tried many different methods and yet no avail. I tried to give the plots different names by adding the corresponding channel names in the local code chunk in "fig.path =". It did not work. I tried this method by setting it in the set up chunk. Still, it did not work. I want to emphasize that my partner and I generated a total of 10 plots for each report. During this trying process, I had more than 100 plots saved in the designated folder. I am not sure if GitHub is able to find the right plot out of so many plots for the right place in the right report though. 
   
3. What are your big take-aways from this project?
   
   I learnt a lot of things about automating reports and how convenient it is to run those automated reports if I would like to update something frequently. I learnt what Dr. Post meant by commit/merge conflicts working with a partner together on repo. At first, I am scared of those because my experience with GitHub has not been pleasant, and I still cannot grasp how it functions. But slowly and surely, I understand how powerful GitHub is and why so many people are using it for projects and collaborative work. However, after experiencing some commit/merge issues, GitHub does a great job telling me where the conflicted sections are by highlighting them with erroneous syntax. I thought I had to find them in a million code chunks that my partner and I created. Turned out, it is so easy. Collaborative work is not as bad as I thought. Ha!
   
   By reading the study paper to learn more about our data and subjects, I learnt the cruel truth about online news and how influential they can be. I think the world is changing, to be better or worse, I don't know. But, I think nowadays, people need to stay away from social media if they need be. Everything has pros and cons. News have to facts, but it is up to the content providers whether or not they want to publish certain news as long as the news they published are facts. It is subjective. However, it is up to people to choose the neutral zone content providers if there are some. 
   
   This project also got me thinking, three weeks ago, Texas A&M versus Alabama football game. During pre-game show, all the commentors and statistics all predicted A&M to lose, by a large, blow-out game. I believe no one picked A&M to win (hardcore fans maybe) judging by their performance from previous two games. Since their starting quarterback got injured in the early season, the commentators and everyone said, "Texas A&M doesn't have a quarterback. They are in trouble". Backup quarterback Calzada received so many negative comments about his performance, even I judged him too prior Alabama game. But man, he did great in that game against Alabama. As matter of fact, everyone did such a great job since football is a team sport. In that game, defense, offense, even special team all contributed to their eventual win over Alabama, then-ranked-number-one team in the nation. My point is, Calzada must have known people were judging his aweful performance before Alabama game. How did he manage to focus on his practice and tune off all the negativities around him? This is what I meant by with the power of internet, sometimes, people just need to turn away from the influential news if they need to. 
   
### Contact me

[cwang51@ncsu.edu](mailto:cwang51@ncsu.edu) 
or 
[peachgal99@gmail.com](mailto:peachgal99@gmail.com)
